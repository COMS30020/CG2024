During the rasterisation workbooks, we encountered difficulties when attempting to texture map 3D objects using 2D drawing functions. The problem was that, due to the fact that our texture drawing functions did not take into account z depth of model artefacts, it was not possible to incorporate the effects of perspective in our renders. It is _possible_ to "correct" the perspective of rasterised textures (by using quite a complex formula). However, rendering perspective correct textures using a ray tracer is MUCH easier (once you understand Gouraud or Phong shading, it's actually almost trivial !)

The basic principle is to use the `u`, `v` and `w` proportional distances derived from calculating the closest intersection in order to calculate the position of the required pixel from the texture map. Just as it is possible to calculate a weighted average pixel colour (as shown in the animation above), it is also possible to determine the location of the "donor" pixel from the texture map - by simply calculating a weighted average of vertex texture points.

As one student who previously took this unit once observed: "Barycentric coordinates are great - once you have implemented them, you get perspective corrected texture mapping for free !"